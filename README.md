# retail_hiring_bias_audit: Retail Hiring Suggestions Audit with OpenAI on Age x Gender x Education

<!-- OpenAI and vllm-based orchestration for bulk batch processing and analysis -->
<!-- - `OpenAI`: OpenAI Batch API-based orchestration for generating prompts, formatted as JSONL files, and submitting them for single-prompt permutation experiments -->
This repository focuses on auditing potential biases in retail hiring suggestions generated by LLMs, using responses from OpenAI's API-based orchestration. The notebooks facilitate bulk prompt generation, saving them in `.jsonl` files for submission to OpenAI via Batchwizard, and perform analysis of responses across factors such as age, gender, and education. The goal is to identify and understand potential biases in hiring recommendations across these variables.


## Getting Started
1. Clone the repository:
    ```
    git clone https://github.com/CharisseHao/retail_hiring_bias_audit.git
    ```
2. Navigate to the project directory:
    ```
    cd retail_hiring_bias_audit
    ```

To replicate the environment, follow one of the options below:
### Option 1: Recreate the Conda Environment
Ensure that you have Conda installed before proceeding with this option.
1. Create a Conda environment from the `environment.yml` file:
    ```
    conda env create -f environment.yml
    ```
2. Activate the environment:
    ```
    conda activate retail-hiring-bias
    ```

### Option 2: Use `pip` and `requirements.txt` 
Ensure that you have `pip` installed before proceeding with this option.
1. Install the required packages specified in the `requirements.txt` file using pip:
    ```
    pip install -r requirements.txt
    ```

## Descriptions and Instructions:
1. `step1_prompt_bulk_generator.ipynb`
    - Inputs `input_data\audit_names.xlsx` and generates prompts in OpenAI Batch `.jsonl` format
        - These must be submitted to the [OpenAI Batch API](https://platform.openai.com/batches), or for open-weight models, they can be submitted using [vllm batch](https://github.com/vllm-project/vllm/blob/main/examples/offline_inference_openai.md). 
        - The files are large, so they are stored as `.zip` files in GitHub. To replicate this process with OpenAI or vllm, unzip these files and submit only the raw `.jsonl` file.
    - Prompt Submission Instructions:
        1. Set your API key by replacing `YOUR_SECRET_KEY` with your actual key:
            ```
            batchwizard configure --set-key YOUR_SECRET_KEY
            ```
        2. Navigate to the directory containing the prompt files:
            ```
            cd input_data/batch_requests
            ```
        3. Submit the prompt file:
            ```
            batchwizard process age_name_edu_gpt-4o-mini-2024-07-18.jsonl
            ```
    - Download Results:
        1. Once the request is processed, OpenAI (or vllm) will return a result `.jsonl` file. To download the result, replace `JOB_ID` with the actual Job ID:
            ```
            batchwizard download JOB_ID
            ```
        2. Move the downloaded result file into the `output_data` folder.
2. `step2_parse_clean_data.ipynb`
    - Reads all `.jsonl` or `.jsonl.zip` files in the `output_data` folder, extracts the percentage values from the responses, and stores all cleaned data into `processed_data/age_name_edu_data.csv.zip`
3. `step3_analysis.ipynb`
    - Reads `processed_data/age_name_edu_data.csv.zip` and performs analyses
4. `Tests` folder:
    - Contains unit tests for the `parse_percentage` function located in `percentparser.py`
    - To run tests, use the following command:
        ```
        python tests/test_parse_percentage.py
        ```
